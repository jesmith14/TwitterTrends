{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! In this Jupyter notebook, you will find code to:\n",
    "\n",
    "1. Scrape Twitter data and store it into an AWS DynamoDB\n",
    "2. Clean Twitter data and calculate metrics from tweeted hashtags, like z scores\n",
    "3. Train a SGD classifier to predict if a tweeted hashtag is trending or not\n",
    "4. Analyze the output of SGD classifier's coefficients to perform feature engineering and find the most accurate model\n",
    "\n",
    "To learn more about Twitter's trend algorithm, trend manipulation, and the methodology behind this work, check out the [GitHub repo](https://github.com/jesmith14/TwitterTrends)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrape Twitter Data Into a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect all of the data you'll need for this workbook from Twitter, run the cell below as a separate Python script on your local machine. You will need to do three things:\n",
    "1. Update the values in the TwitterAPI class to be your personal Twitter Developer API keys\n",
    "2. Run the code in the same folder as your .aws folder with your personal AWS configuration details\n",
    "    - you will need to create 2 AWS DynamoDBs (free tier eligible), name one 'TweetStream' with a numerical ID (tweet ID), name the other 'trendTable' with a string ID (time stamp)\n",
    "3. To download all of the Twitter data into csvs, I used the DynamoDBtoCSV package. You can also skip this step and simply use the csvs I used in this workbook by downloading them from the GitHub repo\n",
    "\n",
    "*For additional guidance, check out the [GitHub repo](https://github.com/jesmith14/TwitterTrends)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Treat this cell as its own python file, follow instructions to run on your own machine\n",
    "#Or you can download the python file from the github repository\n",
    "import datetime\n",
    "import calendar\n",
    "import tweepy\n",
    "import json\n",
    "import boto3\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "class TwitterAPI():\n",
    "    def __init__(self):\n",
    "        self.api_key = 'INSERT_TWITTER_API_KEY_HERE'\n",
    "        self.api_secret = 'INSERT_TWITTER_API_SECRET_KEY_HERE'\n",
    "        self.access_token = 'INSERT_TWITTER_API_ACCESS_TOKEN_HERE'\n",
    "        self.access_secret = 'INSTER_TWITTER_SECRET_ACCESS_TOKEN_HERE'\n",
    "        self.auth = tweepy.OAuthHandler(self.api_key, self.api_secret)\n",
    "        self.auth.set_access_token(self.access_token, self.access_secret)\n",
    "        self.api = tweepy.API(self.auth)\n",
    "        self.trendTable = DataBase().trendTable\n",
    "\n",
    "    def addTrendsToDB(self):\n",
    "        api = self.api\n",
    "        currentTrends = api.trends_place(1)[0]\n",
    "        d1 = datetime.datetime.strptime(currentTrends['created_at'],\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        calendar.month_name[d1.month][:3]\n",
    "        new_format = calendar.month_name[d1.month][:3] + \" %d %H:%M\"\n",
    "        time = d1.strftime(new_format)\n",
    "        trends = set()\n",
    "        for trend in currentTrends['trends']:\n",
    "            trends.add(trend['name'])\n",
    "        print('* time: ', time)\n",
    "        self.trendTable.put_item(\n",
    "            Item={\n",
    "                'id':time,\n",
    "                'trends':trends\n",
    "            }\n",
    "        )\n",
    "\n",
    "class DataBase():\n",
    "    def __init__(self):\n",
    "        self.dynamodb = boto3.resource('dynamodb', region_name='us-east-2')\n",
    "        self.client = boto3.client('dynamodb', region_name='us-east-2')\n",
    "        self.tweetTable = self.dynamodb.Table('TweetStream')\n",
    "        self.trendTable = self.dynamodb.Table('trendTable')\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self):\n",
    "        self.tweet_count = 0\n",
    "        self.word_counts = {}\n",
    "        self.totals = {}\n",
    "\n",
    "        self.tweetTable = DataBase().tweetTable\n",
    "\n",
    "        \n",
    "    def addNewTweetToDB(self, newData):\n",
    "        #add the new tweet json to the DB (new tweet DB)\n",
    "        print(\"# :\" + newData['time'] + newData['text'][:5] + \"...\")\n",
    "        self.tweetTable.put_item(\n",
    "           Item={\n",
    "                'id': newData['id'],\n",
    "                'time': newData['time'],\n",
    "                'text': newData['text']\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            #returning False in on_data disconnects the stream\n",
    "            return False\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        self.tweet_count += 1\n",
    "        if self.tweet_count % 10 == 0:\n",
    "            data = json.loads(data)\n",
    "            if'text' in data:\n",
    "                newData = {}\n",
    "                newData['text'] = data['text']\n",
    "                newData['time'] = data['created_at'][4:16]\n",
    "                newData['id'] = data['id']\n",
    "                self.addNewTweetToDB(newData)\n",
    "\n",
    "def gatherTweets():\n",
    "    print('gathering tweets...')\n",
    "    myListener = MyStreamListener()\n",
    "    api = TwitterAPI()\n",
    "    myStream = tweepy.Stream(auth=api.auth, listener=myListener)\n",
    "    myStream.sample()\n",
    "\n",
    "def gatherTrends():\n",
    "    print('gathering trends...')\n",
    "    threading.Timer(300.0, gatherTrends).start()\n",
    "    api = TwitterAPI()\n",
    "    api.addTrendsToDB()\n",
    "\n",
    "def main():\n",
    "    print('running')\n",
    "    if(sys.argv[1] == 'Tweets'):\n",
    "        gatherTweets()\n",
    "    elif(sys.argv[1] == 'Trends'):\n",
    "        gatherTrends()\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step can be done in many different ways, here I chose to create different dataframes and dictionaries throughout the cleaning / data preprocessing so that it would be easier to see what I am calculating and changing at each step, but the final product could be obtained by taking many more shortcuts that I chose to not take.\n",
    "\n",
    "**Be careful when running some of these cells, a few of them will take several minutes to run. Most cells have a time stamp that will print out to keep track of how long there is left to go**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#csvs created from my AWS DynamoDB using the DynamoDBtoCSV package\n",
    "trends = pd.read_csv('trends.csv')\n",
    "tweets = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creating and formatting the trends dataframe:\n",
    "\n",
    "|timeStamp [string] | trends [list of hashtags] |\n",
    "\n",
    "'''\n",
    "def getHashtags(trends):\n",
    "    trendsWithoutQuotes = trends.replace('\"', '')\n",
    "    trendsStripped = trendsWithoutQuotes.strip('[]')\n",
    "    trendList = trendsStripped.split()\n",
    "    hashtags = []\n",
    "    for item in trendList:\n",
    "        if(item[0] == '#'):\n",
    "            hashtags.append(item)\n",
    "\n",
    "\n",
    "    return hashtags\n",
    "\n",
    "import numpy as np\n",
    "formattedTrends = trends[:2761].copy()\n",
    "tester = []\n",
    "for i in range(0, len(trends) - 2): \n",
    "    hashTagList = getHashtags(trends.iloc[i]['trends'])\n",
    "    formattedTrends.iloc[i]['trends'] = hashTagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec 06 11:53</td>\n",
       "      <td>[#BuenViernes,#DiscoRajaTeaser,#Encounter,#Flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec 06 15:30</td>\n",
       "      <td>[#6DElParoSigue,#6Dic,#AdoreYou,#BroadwayinHaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dec 06 07:48</td>\n",
       "      <td>[#AdoreYou,#AllAboutLuvForWonho,#AnxietyFeelsL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dec 07 22:46</td>\n",
       "      <td>[#370MilyonNerede,#7DEstoRecienEmpieza,#AJRuiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dec 08 03:24</td>\n",
       "      <td>[#ACCFCG,#AChristmasLoveStory,#AltasHoras,#Ani...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                             trends\n",
       "0  Dec 06 11:53  [#BuenViernes,#DiscoRajaTeaser,#Encounter,#Flo...\n",
       "1  Dec 06 15:30  [#6DElParoSigue,#6Dic,#AdoreYou,#BroadwayinHaw...\n",
       "2  Dec 06 07:48  [#AdoreYou,#AllAboutLuvForWonho,#AnxietyFeelsL...\n",
       "3  Dec 07 22:46  [#370MilyonNerede,#7DEstoRecienEmpieza,#AJRuiz...\n",
       "4  Dec 08 03:24  [#ACCFCG,#AChristmasLoveStory,#AltasHoras,#Ani..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formattedTrends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Careful, the cell below can take around 5 minutes to run!**\n",
    "\n",
    "It will stop after 800000 prints out below the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweetID</th>\n",
       "      <th>time</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[#WangXian, #MoDaoZuShi, #魔道祖师]</td>\n",
       "      <td>1203236748953706500</td>\n",
       "      <td>Dec 07 08:56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[#XiaoZhan, #เซียวจ้าน, #샤오잔, #シャオジャン]</td>\n",
       "      <td>1203667751438413800</td>\n",
       "      <td>Dec 08 13:28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[#FNS歌謡祭, #ジェジュン, #チキンライス, #OH_MY_LITTLE_GIRL]</td>\n",
       "      <td>1202185203382247400</td>\n",
       "      <td>Dec 04 11:17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[#Live]</td>\n",
       "      <td>1203929832494530600</td>\n",
       "      <td>Dec 09 06:50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[#เป็นสเตจแรกของDoyouที่โคตรมัน, #BamBam]</td>\n",
       "      <td>1204299484915650600</td>\n",
       "      <td>Dec 10 07:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         hashtags              tweetID  \\\n",
       "0                 [#WangXian, #MoDaoZuShi, #魔道祖师]  1203236748953706500   \n",
       "1          [#XiaoZhan, #เซียวจ้าน, #샤오잔, #シャオジャン]  1203667751438413800   \n",
       "2  [#FNS歌謡祭, #ジェジュン, #チキンライス, #OH_MY_LITTLE_GIRL]  1202185203382247400   \n",
       "3                                         [#Live]  1203929832494530600   \n",
       "4       [#เป็นสเตจแรกของDoyouที่โคตรมัน, #BamBam]  1204299484915650600   \n",
       "\n",
       "           time  RT  \n",
       "0  Dec 07 08:56   1  \n",
       "1  Dec 08 13:28   1  \n",
       "2  Dec 04 11:17   1  \n",
       "3  Dec 09 06:50   1  \n",
       "4  Dec 10 07:19   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Creating and formatting the tweets dataframe, only selecting hashtags for this dataset for simplicity:\n",
    "\n",
    "| hashtags [string array] | tweetID [integer] | minute timeStamp [string] | RT (0 or 1) |\n",
    "'''\n",
    "\n",
    "#careful, this cell takes a few minutes to run - there are over 800000 tweets to go through!\n",
    "newRows = []\n",
    "#omitting last rows of tweets dataframe because they were query response codes\n",
    "for i in range(0, len(tweets[:800158])):\n",
    "    if((i % 100000) == 0):\n",
    "        print(i)\n",
    "    RT = 0\n",
    "    hashtags = []\n",
    "    currentTweet = tweets.iloc[i]\n",
    "    if isinstance(currentTweet['text'], float) or isinstance(currentTweet['time'], float): continue\n",
    "    for word in currentTweet['text'].split():\n",
    "        if word == \"RT\":\n",
    "            RT = 1\n",
    "        if word[0] == '#':\n",
    "            hashtags.append(word)\n",
    "        else: continue\n",
    "    if len(hashtags) > 0:\n",
    "        thisTweet = np.array([hashtags, tweets.iloc[i]['id'], tweets.iloc[i]['time'], RT])\n",
    "        newRows.append({'hashtags':hashtags, 'tweetID':thisTweet[1], 'time':thisTweet[2], 'RT':thisTweet[3]})\n",
    "\n",
    "hashtags = pd.DataFrame(newRows)\n",
    "hashtags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn all timestamps into Date Times, add time intervals for trends, sort dataframes by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def getDateTimeArray(df, columnName):\n",
    "    datetimes = []\n",
    "    for i in range(len(df)):\n",
    "        date_time_str_test = df.iloc[i][columnName] + ' 2019'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str_test, '%b %d %H:%M %Y')\n",
    "        datetimes.append(date_time_obj)\n",
    "\n",
    "    #appending this to end to make it same length as trends df\n",
    "    datetimes.append(None)\n",
    "    return datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add dateTime column to both dataframes for sorting by time\n",
    "formattedTrends['dateTime'] = getDateTimeArray(formattedTrends[:-1], 'id')\n",
    "hashtags['dateTime'] = getDateTimeArray(hashtags[:-1], 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort formattedTrends by time\n",
    "formattedTrends.sort_values(by='dateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add endTime attribute column\n",
    "formattedTrends['endTime'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in endTime attribute column\n",
    "for index, row in formattedTrends.iterrows():\n",
    "    startTime = row['dateTime']\n",
    "    #end time is 10 minutes after this trend\n",
    "    endTime = startTime + datetime.timedelta(minutes=10)\n",
    "    #if there is a trend array for 10 minutes later, we add this end time to the dataframe\n",
    "    if len(formattedTrends[formattedTrends['dateTime'] == endTime]) > 0:\n",
    "        formattedTrends.at[index, 'endTime'] = endTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formated trends is now a dataframe that only contains trends in the specified 10 minute non-gap intervals\n",
    "formattedTrends = formattedTrends[formattedTrends['endTime'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort hashtags by time\n",
    "hashtags.sort_values(by='dateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataframe of all the hashtags as their own row\n",
    "totalHashtags = hashtags.explode('hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalHashtags['trending'] = None\n",
    "#creating unique index for each hashtag in the dataset\n",
    "indexes = list(range(len(totalHashtags)))\n",
    "totalHashtags['index'] = indexes\n",
    "totalHashtags.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n"
     ]
    }
   ],
   "source": [
    "#here I am going through the hashtags dataframe and labeling each hashtag with a 0 if it was used \n",
    "#when it wasn't trending and with a 1 if it was used when it was trending\n",
    "#this is if it was or wasn't trending in the specified 10 minute window of trends that the tweet occured during\n",
    "#this cell will print a timestamp to check that it's running properly, and will stop after 500,000 prints out\n",
    "timeTable = 0\n",
    "for index1, row1 in formattedTrends.iterrows():\n",
    "    startTime = row1['dateTime']\n",
    "    trendList = list(formattedTrends[formattedTrends['dateTime'] == startTime]['trends'])[0][0]\n",
    "    thisTime = startTime\n",
    "    for i in range(1, 11):\n",
    "        for index, row in (totalHashtags[totalHashtags['dateTime'] == thisTime]).iterrows():\n",
    "            if row['hashtags'] in trendList:\n",
    "                trending = 1\n",
    "            else:\n",
    "                trending = 0\n",
    "            totalHashtags.at[index, 'trending'] = trending\n",
    "            #here to keep track of running time\n",
    "            timeTable += 1\n",
    "            if(timeTable % 100000 == 0):\n",
    "                print(timeTable)\n",
    "        thisTime = startTime + datetime.timedelta(minutes=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of some formatting errors, omitting NaN values\n",
    "totalHashtags = totalHashtags[totalHashtags['trending'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformatting dataframe to have unique index and sorted by time\n",
    "totalHashtags.reset_index(inplace=True)\n",
    "totalHashtags.sort_values(by='dateTime', inplace=True)\n",
    "indexes = list(range(len(totalHashtags)))\n",
    "totalHashtags['index'] = indexes\n",
    "totalHashtags.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweetID</th>\n",
       "      <th>time</th>\n",
       "      <th>RT</th>\n",
       "      <th>dateTime</th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#笑う門には大澤駿弥</td>\n",
       "      <td>1200966846154858500</td>\n",
       "      <td>Dec 01 02:36</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-01 02:36:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#大澤駿弥</td>\n",
       "      <td>1200966846154858500</td>\n",
       "      <td>Dec 01 02:36</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-01 02:36:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#MamangamFestFromDec12</td>\n",
       "      <td>1200966930007412700</td>\n",
       "      <td>Dec 01 02:36</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-01 02:36:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#WorldAIDSDay</td>\n",
       "      <td>1200967081040081000</td>\n",
       "      <td>Dec 01 02:37</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-01 02:37:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ただのいちごじゃない</td>\n",
       "      <td>1202058204026306600</td>\n",
       "      <td>Dec 04 02:53</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-04 02:53:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hashtags              tweetID          time  RT  \\\n",
       "index                                                                  \n",
       "0                  #笑う門には大澤駿弥  1200966846154858500  Dec 01 02:36   0   \n",
       "1                       #大澤駿弥  1200966846154858500  Dec 01 02:36   0   \n",
       "2      #MamangamFestFromDec12  1200966930007412700  Dec 01 02:36   1   \n",
       "3               #WorldAIDSDay  1200967081040081000  Dec 01 02:37   0   \n",
       "4                 #ただのいちごじゃない  1202058204026306600  Dec 04 02:53   1   \n",
       "\n",
       "                 dateTime trending  \n",
       "index                               \n",
       "0     2019-12-01 02:36:00        0  \n",
       "1     2019-12-01 02:36:00        0  \n",
       "2     2019-12-01 02:36:00        0  \n",
       "3     2019-12-01 02:37:00        0  \n",
       "4     2019-12-04 02:53:00        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalHashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232134"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(totalHashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweetID</th>\n",
       "      <th>time</th>\n",
       "      <th>RT</th>\n",
       "      <th>dateTime</th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ただのいちごじゃない</td>\n",
       "      <td>1202058204026306600</td>\n",
       "      <td>Dec 04 02:53</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-04 02:53:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#三角チョコパイあまおう</td>\n",
       "      <td>1202058204026306600</td>\n",
       "      <td>Dec 04 02:53</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-04 02:53:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hashtags              tweetID          time  RT  \\\n",
       "index                                                        \n",
       "4       #ただのいちごじゃない  1202058204026306600  Dec 04 02:53   1   \n",
       "5      #三角チョコパイあまおう  1202058204026306600  Dec 04 02:53   1   \n",
       "\n",
       "                 dateTime trending  \n",
       "index                               \n",
       "4     2019-12-04 02:53:00        0  \n",
       "5     2019-12-04 02:53:00        0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalHashtags[totalHashtags['dateTime'] == '2019-12-04 02:53']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting information to add to the trending dataframe so I know how many trending hashtags there were in each\n",
    "#10 minute window and how many total hashtags there were\n",
    "numTrendsInTweets = []\n",
    "numTotalHashtags = []\n",
    "for index,row in formattedTrends.iterrows():\n",
    "    \n",
    "    startTime = row['dateTime']\n",
    "    thisTime = startTime\n",
    "    numTrends = 0\n",
    "    numTotal = 0\n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        hashtagsAtMinute = totalHashtags[totalHashtags['dateTime'] == thisTime]\n",
    "        for index2, row2, in hashtagsAtMinute.iterrows():\n",
    "            if row2['trending'] == 1:\n",
    "                numTrends += 1\n",
    "            numTotal += 1\n",
    "        thisTime = startTime + datetime.timedelta(minutes=i)\n",
    "    numTrendsInTweets.append(numTrends)\n",
    "    numTotalHashtags.append(numTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "formattedTrends['NumTrendsTweeted'] = numTrendsInTweets\n",
    "formattedTrends['TotalHashtags'] = numTotalHashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.770048737261853"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average number of times a trending hashtag was used in each 10 minute bucket in this dataset\n",
    "np.mean(formattedTrends['NumTrendsTweeted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243.38901196278246"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average number of hashtags that were tweeted in each 10 minute bucket in this dataset\n",
    "np.mean(formattedTrends['TotalHashtags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling the dataset so that there will be an equal amount of trends and non-trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "#creating dictionaries that for every 10 minute window:\n",
    "#there is a list of the trends from that window,\n",
    "#a list of the hashtags that were tweeted that were trending,\n",
    "#and a list of randomly selected hashtags that were tweeted that were not trending (same amount as trending hashtags)\n",
    "timeStamp = 0\n",
    "z_score_dict = {}\n",
    "for index,row in formattedTrends.iterrows():\n",
    "    currentTrends = row['trends']\n",
    "    if row['TotalHashtags'] < 10: continue\n",
    "    if row['TotalHashtags'] < (2*row['NumTrendsTweeted']): continue\n",
    "    elif row['TotalHashtags'] >= (2*row['NumTrendsTweeted']):\n",
    "        #randomly sample sampleSize of hashtags that weren't trending from this 10 minute window\n",
    "        startTime = row['dateTime']\n",
    "        thisTime = startTime\n",
    "        if startTime not in z_score_dict:\n",
    "            z_score_dict[startTime] = {'trends': currentTrends, 'tweetedTrends': [], 'tweetedNonTrends':[]}\n",
    "        for i in range(1, 11):\n",
    "            hashtagsAtMinute = totalHashtags[totalHashtags['dateTime'] == thisTime]\n",
    "            for index2, row2, in hashtagsAtMinute.iterrows():\n",
    "                if row2['trending'] == 1:\n",
    "                    z_score_dict[startTime]['tweetedTrends'].append(row2['hashtags'])\n",
    "                if row2['trending'] == 0 and len(z_score_dict[startTime]['tweetedNonTrends']) < row['NumTrendsTweeted']:\n",
    "                    z_score_dict[startTime]['tweetedNonTrends'].append(row2['hashtags'])\n",
    "            thisTime = startTime + datetime.timedelta(minutes=i)\n",
    "    timeStamp += 1\n",
    "    if timeStamp % 500 == 0:\n",
    "        print(timeStamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation Time! The next few cells are calculating all the metrics needed to find the z_score from the last hour for every hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2500\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "#coming up with a count for how many times trending hashtags were tweeted in the last hour\n",
    "#and how many times non trending hashtags were tweeted in the last hour\n",
    "#also creating a count for how many hashtags total were tweeted in the last hour for proportions later\n",
    "#using a time stamp, this cell will stop after 3000 prints\n",
    "for key in z_score_dict:\n",
    "    numTrendTags = len(z_score_dict[key]['tweetedTrends'])\n",
    "    z_score_dict[key]['trendCounts'] = [0]*numTrendTags\n",
    "    z_score_dict[key]['nonTrendCounts'] = [0]*numTrendTags\n",
    "    z_score_dict[key]['totalCounts'] = 0\n",
    "    for i in range(numTrendTags):\n",
    "        itemtrend = z_score_dict[key]['tweetedTrends'][i]\n",
    "        itemnontrend = z_score_dict[key]['tweetedNonTrends'][i]\n",
    "        for k in range(0, 61):\n",
    "            minute = key - datetime.timedelta(minutes=k)\n",
    "            if minute in z_score_dict: \n",
    "                if itemtrend in z_score_dict[minute]['tweetedTrends']:\n",
    "                    z_score_dict[key]['trendCounts'][i] += 1\n",
    "                    z_score_dict[key]['totalCounts'] += 1\n",
    "                if itemnontrend in z_score_dict[minute]['tweetedNonTrends']:\n",
    "                    z_score_dict[key]['nonTrendCounts'][i] += 1\n",
    "                    z_score_dict[key]['totalCounts'] += 1\n",
    "    timeStamp += 1\n",
    "    if timeStamp % 500 == 0:\n",
    "        print(timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "#calculate proportion count for each item\n",
    "#cell will stop running when time stamp prints out 4500\n",
    "timeStamp = 0\n",
    "for item in z_score_dict:\n",
    "    numTags = len(z_score_dict[item]['tweetedTrends'])\n",
    "    z_score_dict[item]['trendCountProportion'] = [0] * numTags\n",
    "    z_score_dict[item]['nonTrendCountProportion'] = [0] * numTags\n",
    "    for i in range(numTags):\n",
    "        if(z_score_dict[item]['totalCounts'] == 0):\n",
    "            print(item)\n",
    "            break\n",
    "        #z_score = (count proportion - mean) / standard deviation\n",
    "        trendCountProportion = z_score_dict[item]['trendCounts'][i] / z_score_dict[item]['totalCounts']\n",
    "        nonTrendCountProportion = z_score_dict[item]['nonTrendCounts'][i] / z_score_dict[item]['totalCounts']\n",
    "        z_score_dict[item]['trendCountProportion'][i] = trendCountProportion\n",
    "        z_score_dict[item]['nonTrendCountProportion'][i] = nonTrendCountProportion\n",
    "        \n",
    "    timeStamp += 1\n",
    "    if timeStamp % 500 == 0:\n",
    "        print(timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "#get total count proportions from past hour to calculate mean proportion count and standard deviation for each item\n",
    "timeStamp = 0\n",
    "for item in z_score_dict:\n",
    "    numTags = len(z_score_dict[item]['tweetedTrends'])\n",
    "    z_score_dict[item]['hourTrendCounts'] = [[]] * numTags\n",
    "    z_score_dict[item]['hourNonTrendCounts'] = [[]] * numTags\n",
    "    for i in range(numTags):\n",
    "        trendingTag = z_score_dict[item]['tweetedTrends'][i]\n",
    "        nonTrendingTag = z_score_dict[item]['tweetedNonTrends'][i]\n",
    "        for k in range(0, 61):\n",
    "            minute = item - datetime.timedelta(minutes=k)\n",
    "            if minute in z_score_dict: \n",
    "                if trendingTag in z_score_dict[minute]['tweetedTrends']:\n",
    "                    indexOfTag = z_score_dict[minute]['tweetedTrends'].index(trendingTag)\n",
    "                    newTrendCount = z_score_dict[minute]['trendCountProportion'][indexOfTag]\n",
    "                    z_score_dict[item]['hourTrendCounts'][i].append(newTrendCount)\n",
    "                if nonTrendingTag in z_score_dict[minute]['tweetedNonTrends']:\n",
    "                    indexOfTag = z_score_dict[minute]['tweetedNonTrends'].index(nonTrendingTag)\n",
    "                    newTrendCount = z_score_dict[minute]['nonTrendCountProportion'][indexOfTag]\n",
    "                    z_score_dict[item]['hourNonTrendCounts'][i].append(newTrendCount)\n",
    "    timeStamp += 1\n",
    "    if timeStamp % 500 == 0:\n",
    "        print(timeStamp)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "#add mean, standard deviation, and z_scores for each trending and nontrending hashtag in the dictionary\n",
    "timeStamp = 0\n",
    "for item in z_score_dict:\n",
    "    numTags = len(z_score_dict[item]['tweetedTrends'])\n",
    "    z_score_dict[item]['trend_mean'] = [0] * numTags\n",
    "    z_score_dict[item]['trend_stddev'] = [0] * numTags\n",
    "    z_score_dict[item]['trend_z_score'] = [0] * numTags\n",
    "    z_score_dict[item]['non_trend_mean'] = [0] * numTags\n",
    "    z_score_dict[item]['non_trend_stddev'] = [0] * numTags\n",
    "    z_score_dict[item]['non_trend_z_score'] = [0] * numTags\n",
    "    for i in range(numTags):\n",
    "        \n",
    "        #trending\n",
    "        trend_x = z_score_dict[item]['trendCountProportion'][i]\n",
    "        trend_mean = np.mean(z_score_dict[item]['hourTrendCounts'][i])\n",
    "        trend_stddev = np.std(z_score_dict[item]['hourTrendCounts'][i])\n",
    "        if trend_stddev == 0:\n",
    "            trend_z_score = 0\n",
    "        else:\n",
    "            trend_z_score = (trend_x - trend_mean) / trend_stddev\n",
    "        z_score_dict[item]['trend_mean'][i] = trend_mean\n",
    "        z_score_dict[item]['trend_stddev'][i] = trend_stddev\n",
    "        z_score_dict[item]['trend_z_score'][i] = trend_z_score\n",
    "        \n",
    "        #nontrending\n",
    "        nontrend_x = z_score_dict[item]['nonTrendCountProportion'][i]\n",
    "        nontrend_mean = np.mean(z_score_dict[item]['hourNonTrendCounts'][i])\n",
    "        nontrend_stddev = np.std(z_score_dict[item]['hourNonTrendCounts'][i])\n",
    "        if nontrend_stddev == 0:\n",
    "            nontrend_z_score = 0\n",
    "        else:\n",
    "            nontrend_z_score = (nontrend_x - nontrend_mean) / nontrend_stddev\n",
    "        z_score_dict[item]['non_trend_mean'][i] = nontrend_mean\n",
    "        z_score_dict[item]['non_trend_stddev'][i] = nontrend_stddev\n",
    "        z_score_dict[item]['non_trend_z_score'][i] = nontrend_z_score\n",
    "        \n",
    "    timeStamp += 1\n",
    "    if timeStamp % 500 == 0:\n",
    "        print(timeStamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Reference:\n",
    "\n",
    "#### Explanation of every attribute calculated and stored in the z_score_dictionary:\n",
    "- *key*: date time for this 10 minute interval\n",
    "- trends: list of all the trends from this timeStamp\n",
    "- tweetedTrends: list of all hashtags that were tweeted in this 10 minute window that were in trends list\n",
    "- tweetedNonTrends: randomly selected list of hashtags that were tweeted in this 10 minute window that were not in the trends list\n",
    "    - this list is the same length as the tweetedTrends list\n",
    "- trendCounts: list of all counts of a hashtag tweeted while trending at index i in the last hour\n",
    "- nonTrendCounts: list of all counts of a hashtag tweeted while not trending at index i in the last hour\n",
    "- totalCounts: number of all hashtags in this dataset that were tweeted in the last hour\n",
    "- trendCountProportion: list of all proportion of counts of a hashtag tweeted while trending at index i in the last hour\n",
    "- nonTrendCountProportion: list of all proportion of counts of a hashtag tweeted while not trending at index i in the last hour\n",
    "- hourTrendCounts: list of lists, where each inner list at index i holds all the proportion of counts for this trending hashtag in the last hour\n",
    "- hourNonTrendCounts: list of lists, where each inner list at index i holds all the proportion of counts for this nontrending hashtag in the last hour\n",
    "- trend_mean: list that contains all the means of occurences in the last hour for every hashtag in tweetedTrends\n",
    "- non_trend_mean: list that contains all the means of occurences in the last hour for every hashtag in tweetedNonTrends\n",
    "- trend_stddev: list that contains all the standard deviations of occurences in the last hour for every hashtag in tweetedTrends\n",
    "- non_trend_stddev: list that contains all the standard deviations of occurences in the last hour for every hashtag in tweetedNonTrends\n",
    "- trend_z_score: list that contains the z_score of the last hour for every hashtag in tweetedTrends\n",
    "- non_trend_z_score: list that contains the z_score of the last hour for every hashtag in tweetedNonTrends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the final training dataframe and testing array for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#gathering all necessary data to create the final training data\n",
    "#so each hashtag in the dataset has a row in the training dataframe\n",
    "#the y values will be the trending label \n",
    "#(0 if the hashtag was not a trend when it was tweeted, and 1 if the hashtag was a trend when it was tweeted)\n",
    "indexes = []\n",
    "hashtags = []\n",
    "startTimes = []\n",
    "endTimes = []\n",
    "means = []\n",
    "stddevs = []\n",
    "z_scores = []\n",
    "trendings = []\n",
    "counts = []\n",
    "i = 0\n",
    "timeStamp = 0\n",
    "for index,row in formattedTrends.iterrows():\n",
    "    startTime = row['dateTime']\n",
    "    endTime = row['endTime']\n",
    "    minute = startTime\n",
    "    for m in range(0, 10):\n",
    "        if minute in z_score_dict:\n",
    "            numTags = len(z_score_dict[minute]['trendCounts'])\n",
    "            for j in range(numTags):\n",
    "                #trend\n",
    "                hashtag = z_score_dict[minute]['tweetedTrends'][j]\n",
    "                hashtags.append(hashtag)\n",
    "                startTime = int(round(minute.timestamp() * 1000))\n",
    "                startTimes.append(startTime)\n",
    "                endTime = int(round((minute + datetime.timedelta(minutes=10)).timestamp() * 1000))\n",
    "                endTimes.append(endTime)\n",
    "                mean = z_score_dict[minute]['trend_mean'][j]\n",
    "                means.append(mean)\n",
    "                stddev = z_score_dict[minute]['trend_stddev'][j]\n",
    "                stddevs.append(stddev)\n",
    "                z_score = z_score_dict[minute]['trend_z_score'][j]\n",
    "                z_scores.append(z_score)\n",
    "                trendings.append(1)\n",
    "                count = z_score_dict[minute]['trendCountProportion'][j]\n",
    "                counts.append(count)\n",
    "                indexes.append(i)\n",
    "                i+=1\n",
    "                \n",
    "                #nontrend\n",
    "                hashtag = z_score_dict[minute]['tweetedNonTrends'][j]\n",
    "                hashtags.append(hashtag)\n",
    "                startTime = int(round(minute.timestamp() * 1000))\n",
    "                startTimes.append(startTime)\n",
    "                endTime = int(round((minute + datetime.timedelta(minutes=10)).timestamp() * 1000))\n",
    "                endTimes.append(endTime)\n",
    "                mean = z_score_dict[minute]['non_trend_mean'][j]\n",
    "                means.append(mean)\n",
    "                stddev = z_score_dict[minute]['non_trend_stddev'][j]\n",
    "                stddevs.append(stddev)\n",
    "                z_score = z_score_dict[minute]['non_trend_z_score'][j]\n",
    "                z_scores.append(z_score)\n",
    "                trendings.append(0)\n",
    "                count = z_score_dict[minute]['nonTrendCountProportion'][j]\n",
    "                counts.append(count)\n",
    "                indexes.append(i)\n",
    "                i+=1\n",
    "            \n",
    "        \n",
    "        minute = minute + datetime.timedelta(minutes=10)\n",
    "        \n",
    "    timeStamp += 1\n",
    "    if timeStamp % 500 == 0: print(timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training data dataframe with all available information\n",
    "data_train_total = pd.DataFrame(columns=['index', 'hashtag','startTime', 'endTime', 'mean', 'stddev', 'z_score', 'count', 'trending'])\n",
    "data_train_total['index'] = indexes\n",
    "data_train_total['hashtag'] = hashtags\n",
    "data_train_total['startTime'] = startTimes\n",
    "data_train_total['endTime'] = endTimes\n",
    "data_train_total['mean'] = means\n",
    "data_train_total['stddev'] = stddevs\n",
    "data_train_total['z_score'] = z_scores\n",
    "data_train_total['count'] = counts\n",
    "data_train_total['trending'] = trendings\n",
    "data_train_total.set_index('index', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>mean</th>\n",
       "      <th>stddev</th>\n",
       "      <th>z_score</th>\n",
       "      <th>count</th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Medevac</td>\n",
       "      <td>1575427980000</td>\n",
       "      <td>1575428580000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#ただのいちごじゃない</td>\n",
       "      <td>1575427980000</td>\n",
       "      <td>1575428580000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Medevac</td>\n",
       "      <td>1575428280000</td>\n",
       "      <td>1575428880000</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.150718</td>\n",
       "      <td>0.073721</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#PasapalabraCHV</td>\n",
       "      <td>1575428280000</td>\n",
       "      <td>1575428880000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#4</td>\n",
       "      <td>1575428280000</td>\n",
       "      <td>1575428880000</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.150718</td>\n",
       "      <td>-0.663489</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               hashtag      startTime        endTime      mean    stddev  \\\n",
       "index                                                                      \n",
       "0             #Medevac  1575427980000  1575428580000  0.500000  0.000000   \n",
       "1          #ただのいちごじゃない  1575427980000  1575428580000  0.500000  0.000000   \n",
       "2             #Medevac  1575428280000  1575428880000  0.211111  0.150718   \n",
       "3      #PasapalabraCHV  1575428280000  1575428880000  0.111111  0.000000   \n",
       "4                   #4  1575428280000  1575428880000  0.211111  0.150718   \n",
       "\n",
       "        z_score     count  trending  \n",
       "index                                \n",
       "0      0.000000  0.500000         1  \n",
       "1      0.000000  0.500000         0  \n",
       "2      0.073721  0.222222         1  \n",
       "3      0.000000  0.111111         0  \n",
       "4     -0.663489  0.111111         1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels for this classifier are trends, 0 if was not trending, 1 if was trending\n",
    "y = trendings\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a classifier to predict Trending hashtags on Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt #1: Using All Features:\n",
    "- startTime\n",
    "- endTime\n",
    "- mean\n",
    "- standard deviation\n",
    "- z_score\n",
    "- count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#omitting labels and hashtag strings in classifier because too many to do word-to-vector conversion in this time frame\n",
    "data_train = data_train_total[['startTime', 'endTime', 'mean', 'stddev', 'z_score', 'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_train, y, test_size=0.2, random_state=0)\n",
    "\n",
    "classifier = SGDClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions_training = classifier.predict(X_train)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.500009\n",
      "Testing accuracy: 0.499964\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %0.6f\" % accuracy_score(y_train, predictions_training))\n",
    "print(\"Testing accuracy: %0.6f\" % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.12359483e+07  4.12360367e+07  1.08150596e+02  6.54579915e+01\n",
      "  -1.20296373e+02  9.38675711e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt #2: Using Only Positive Features:\n",
    "- mean\n",
    "- standard deviation\n",
    "- count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train_total[['mean', 'stddev', 'count']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_train, y, test_size=0.2, random_state=0)\n",
    "\n",
    "classifier = SGDClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions_training = classifier.predict(X_train)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.914482\n",
      "Testing accuracy: 0.914902\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %0.6f\" % accuracy_score(y_train, predictions_training))\n",
    "print(\"Testing accuracy: %0.6f\" % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29.66358858 24.7547925  15.81587896]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt #3: Only Numbers Included in Z_Score Calculation :\n",
    "- mean\n",
    "- standard deviation\n",
    "- count\n",
    "- z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train_total[['mean', 'stddev', 'count', 'z_score']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_train, y, test_size=0.2, random_state=0)\n",
    "\n",
    "classifier = SGDClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions_training = classifier.predict(X_train)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.932666\n",
      "Testing accuracy: 0.932880\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %0.6f\" % accuracy_score(y_train, predictions_training))\n",
    "print(\"Testing accuracy: %0.6f\" % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.38535161 23.66534825 19.42241186 -0.17151434]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Attempt #4: Only Z_Score :\n",
    "- z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train_total[['z_score']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_train, y, test_size=0.2, random_state=0)\n",
    "\n",
    "classifier = SGDClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions_training = classifier.predict(X_train)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.454239\n",
      "Testing accuracy: 0.453876\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %0.6f\" % accuracy_score(y_train, predictions_training))\n",
    "print(\"Testing accuracy: %0.6f\" % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.37620597]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analysis - How To Predict Twitter Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study, the performance metric was sk-learn’s classification_accuracy score, which is the same as a jaccard index score for classification problems. \n",
    "\n",
    "In order to perform feature engineering, I needed to understand which features provided the most weight for the classifier. To do this, I printed the .coef_ metric of the classifier, which provided an array of the final weights of each feature in the model that led to its current accuracy. This helped me decide which features were likely the most important to include in an accurate classifier.\n",
    "\n",
    "I first trained the model using all of the features available, which led to an accuracy of about 50%. Then, using only metrics that were involved in the z score calcuation, the accuracy jumped to about 91%. Using only the z score as a feature, the accuracy dropped to 42%. Finally, the model with the best performance was the one that included only the features that contributed to the z score of a hashtag (including the z score itself), which led to an accuracy of about 93%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Find more information about this study, as well as a report, on the [GitHub repo](https://github.com/jesmith14/TwitterTrends)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
